{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <center>Open Scale Tutorial</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses Python and modern machine learning libraries to predict telco churn using an existing dataset stored within IBM COS. Given CRISP-DM is the industry accepted methodology for working on predictive/statistical challenges, this same approach will be used here.\n",
    "\n",
    "<h2>Prerequisites</h2>\n",
    "<ol>\n",
    "<li>IBM Watson Studio</li>\n",
    "<li>Watson Machine Learning</li>\n",
    "<li>IBM OpenScale</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Data Using IBM COS\n",
    "This section goes through the process of importing training and testing datasets originally uploaded from a CSV into the Notebook. \n",
    "\n",
    "<p><b>1.1</b> To load data into Watson Studio, select the IO button in the top right hand corner of the notebook. </p>\n",
    "<p><img src=\"https://i.imgur.com/dQ1Uf3U.png\" align=\"left\"/></p></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.2</b> Select browse to load your data</p></br>\n",
    "<p><img src=\"https://i.imgur.com/DPg0KhF.png\" align=\"left\" width=800 display=\"inline\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>1.3</b> Choose insert Pandas dataframe to insert new code cell</p></br>\n",
    "<p><img src=\"https://i.imgur.com/7Air7sc.png\" align=\"left\" style=\"height:250px\" display=\"inline\"/></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data as CSV from IBM COS using steps above\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "In this section, we go through key parts of the DS process including reviewing data quality and creating summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View length of data frame\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View unique values within each column\n",
    "for col in df.columns:\n",
    "     print(col, len(df[col].unique()), df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics numerical variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for categorical variables\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns which have less than two variables\n",
    "less_than_2 = []\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 2 and df[col].dtype=='object':\n",
    "        print(col)\n",
    "        less_than_2.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "We can then prepare the data for modelling by one-hot encoding categorical features where required and resolving troublesome data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode columns with less than 2 unique values\n",
    "less_than_2\n",
    "for col in less_than_2:\n",
    "    if col == 'gender':\n",
    "        df[col] = df[col].apply(lambda x: 1 if x=='Female' else 0)\n",
    "    else:\n",
    "         df[col] = df[col].apply(lambda x: 1 if x=='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for blank strings within Total Charges column\n",
    "df[df['Total Charges']==' '].head()\n",
    "df['Total Charges'].replace(' ', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Total Charges column to float\n",
    "df['Total Charges'] = df['Total Charges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap from correlation\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop identifier column\n",
    "df.drop('Customer ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode an entire data frame and store it in a new dataframe called abt\n",
    "abt = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "y = abt['Churn']\n",
    "X = abt.drop('Churn', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing splits\n",
    "random_state=1234\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out training and testing split lengths\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelling\n",
    "Onto modelling whereby we use hyperparameter optimization to tune a range of models to the training data. We ultimately select the best performing model and store it as a saved model to WML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data pipelines\n",
    "pipelines = {\n",
    "     'rf':make_pipeline(StandardScaler(), RandomForestClassifier(random_state=random_state)),\n",
    "     'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=random_state)),\n",
    "     'sgd':make_pipeline(StandardScaler(), SGDClassifier(random_state=random_state)),\n",
    "     'ridge':make_pipeline(StandardScaler(), RidgeClassifier(random_state=random_state))\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HPO Tuning Grid\n",
    "grid = {\n",
    "     'rf':{'randomforestclassifier__n_estimators':[10,20,30]},\n",
    "     'gb':{'gradientboostingclassifier__n_estimators':[10,20,30]},\n",
    "     'sgd':{'sgdclassifier__alpha':[0.5,0.9,0.99]},\n",
    "     'ridge':{'ridgeclassifier__alpha':[0.5,0.9,0.99]}\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models with Cross Validation\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    # 4.1 Create a Grid Search CV instance\n",
    "    model = GridSearchCV(pipeline, grid[algo], cv=10, n_jobs=-1)\n",
    "    # 4.2 Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # 4.3 Save it to the fit models dictionary\n",
    "    fit_models[algo] = model\n",
    "    print(algo, 'model has been fit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation\n",
    "Basic evaluation completed for a logistic regression model. Calculate accuracy, F1 and propagate the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['gb'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print('Acc for', algo, 'is', accuracy_score(y_test, yhat))\n",
    "    print('F1 for', algo, 'is', f1_score(y_test, yhat))\n",
    "    print(algo)\n",
    "    print(confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Deployment\n",
    "This section goes through how to deploy the model to WML. In order to complete this stage you will need to retrieve Service Credentials from Watson Machine Learning. These can be obtained from the Watson Machine Learning service credentials section. \n",
    "\n",
    "<img src=\"https://i.imgur.com/0q6dz1g.png\" width=800 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fit_models['gb'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "    \"url\": \"UPDATE CREDENTIALS\",\n",
    "    \"apikey\": \"UPDATE CREDENTIALS\",\n",
    "    \"instance_id\": \"UPDATE CREDENTIALS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"Scikit Learn Churn Model\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"scikit-learn\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"0.20\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.repository.store_model(model=best_model, meta_props=metadata )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = model_details['metadata']['guid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = client.repository.load(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = client.deployments.create(uid, \"Deployment of Sklearn Churn Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_url(deployment_details)\n",
    "\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = scoring_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = X_test.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload =  {\"fields\":X_test.columns.to_numpy().tolist(),  \"values\":values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = client.deployments.score(url, scoring_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Setup OpenScale\n",
    "Last but not least, setup monitors in OpenScale using the deployed WML model. For this step you will require your cloud API key. This can be retrieved from your IBM Cloud account as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>7.1</b> Navigate to <a href=\"cloud.ibm.com\">cloud.ibm.com</a> and select Manage Users.</p>\n",
    "<p><img src=\"https://i.imgur.com/OqDyije.png\" align=\"left\" style=\"height:400px\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>7.2</b> Select IBM Cloud API Keys then Create an IBM Cloud API Key.</p>\n",
    "<p><img src=\"https://i.imgur.com/II15lyS.png\" align=\"left\" style=\"height:400px\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>7.3</b> Name your key then replace the value in the CLOUD_API_KEY variable below. </p>\n",
    "<p><img src=\"https://i.imgur.com/w9Yj5IW.png\" align=\"left\" style=\"height:400px\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_ai_openscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"UPDATE CREDENTIALS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Watson OpenScale API Key\n",
    "import requests\n",
    "from ibm_ai_openscale.utils import get_instance_guid\n",
    "\n",
    "WOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\n",
    "WOS_CREDENTIALS = {\n",
    "    \"instance_guid\": WOS_GUID,\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "if WOS_GUID is None:\n",
    "    print('Watson OpenScale GUID NOT FOUND')\n",
    "else:\n",
    "    print(WOS_GUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of WOS Client\n",
    "ai_client = APIClient(aios_credentials=WOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Create OpenScale Datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_MY_INTERNAL_POSTGRES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datamart\n",
    "try:\n",
    "    data_mart_details = ai_client.data_mart.get_details()\n",
    "    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n",
    "        if KEEP_MY_INTERNAL_POSTGRES:\n",
    "            print('Using existing internal datamart.')\n",
    "        else:\n",
    "            if DB_CREDENTIALS is None:\n",
    "                print('No postgres credentials supplied. Using existing internal datamart')\n",
    "            else:\n",
    "                print('Switching to external datamart')\n",
    "                ai_client.data_mart.delete(force=True)\n",
    "                ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "    else:\n",
    "        print('Using existing external datamart')\n",
    "except:\n",
    "    if DB_CREDENTIALS is None:\n",
    "        print('Setting up internal datamart')\n",
    "        ai_client.data_mart.setup(internal_db=True)\n",
    "    else:\n",
    "        print('Setting up external datamart')\n",
    "        try:\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "        except:\n",
    "            print('Setup failed, trying Db2 setup')\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS, schema=DB_CREDENTIALS['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mart_details = ai_client.data_mart.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mart_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Bind WML to OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind WML Instance to WOS\n",
    "binding_uid = ai_client.data_mart.bindings.add('WML Binding', WatsonMachineLearningInstance(WML_CREDENTIALS))\n",
    "bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "\n",
    "if binding_uid is None:\n",
    "    binding_uid = [binding['metadata']['guid'] for binding in bindings_details['service_bindings'] if binding['entity']['name']=='WML Cloud Instance'][0]\n",
    "\n",
    "ai_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binding_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ai_client.data_mart.bindings.list_assets(binding_uid=binding_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Create new OpenScale Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Scikit Learn Churn Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete WOS monitor if it already exists\n",
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "for subscription in subscriptions_uids:\n",
    "    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n",
    "    if sub_name == MODEL_NAME:\n",
    "        ai_client.data_mart.subscriptions.delete(subscription)\n",
    "        print('Deleted existing subscription for', MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new monitor\n",
    "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    uid,\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    prediction_column='prediction',\n",
    "    label_column='prediction', \n",
    "    probability_column='probability',\n",
    "    categorical_columns=[],\n",
    "    feature_columns = X_test.columns.to_numpy().tolist()\n",
    "))\n",
    "\n",
    "if subscription is None:\n",
    "    print('Subscription already exists; get the existing one')\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n",
    "            subscription = ai_client.data_mart.subscriptions.get(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review all subscriptions\n",
    "#subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "#ai_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_details = subscription.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Send Feedback Scoring Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = client.deployments.score(url, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "subscription.payload_logging.get_records_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Enable Quality Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "subscription.quality_monitoring.enable(threshold=0.7, min_records=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = X_test.join(y_test).to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.feedback_logging.store(feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Enable Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain = abt\n",
    "explain['prediction'] = explain['Churn']\n",
    "explain.drop('Churn', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.explainability.enable(training_data=explain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
